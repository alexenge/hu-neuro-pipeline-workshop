---
title:          "`hu-neuro-pipeline`"
subtitle: |
  A Python implementation of the single trial EEG pipeline by Frömer et al.
  [*Front. Neurosci.*, -@fromer2018]
author:         "Alexander Enge"
date:           "06/04/2022"
institute:      "Neuro Lab @ Humboldt-Universität zu Berlin"
classoption:    "t"
bibliography:   "references.bib"
csl:            "template/apa.csl"
output:
  beamer_presentation:
    includes:
      in_header: "template/hu_template.tex"
---

```{r, include=FALSE}
# Create helper function to include figures only if the file exists
include_if_exists <- function(path, ...) {
  if (file.exists(here::here(path))) {
    knitr::include_graphics(here::here(path), ...)
  }
}
```

## Why Python?

```{r, echo=FALSE, fig.align="center", message=FALSE, out.width="60%"}
include_if_exists("slides/figures/venn.png")
```

## Why MNE-Python?

- Versatile

  - EEG, MEG, ECoG, fNIRS

  - Preprocessing, statistics, time-frequency analsis, visualization, machine learning, connectivity, source localization, ...

- Open source

  - 288 contributors on GitHub as of April 2022

  - Funding: NIH, NSF, ERC, Google, Amazon, ...

- Community standards

  - Code review, automatic tests, user forum, office hours, ...

## Why this pipeline?

- User friendly, e.g.:

  - No MATLAB license; can be called from within R

  - Outputs readily usable for LMMs and plotting

- New features, e.g.:

  - Time-frequency analysis

  - Automatic ocular correction (ICA) + bad channel detection

- Code standards + versioning \tiny (https://github.com/alexenge/hu-neuro-pipeline/)

\bigskip

```{r, echo=FALSE, fig.align="right", message=FALSE, out.width="30%"}
include_if_exists("slides/figures/github_pypi.png")
```

## Installation

For Python users:

```{bash, eval=FALSE}
# Install via the command line from the Python Packaging Index (PyPI)
python3 -m pip install hu-neuro-pipeline
```

For R users:

```{r, eval=FALSE}
# Install reticulate for interfacing with Python from R
install.packages("reticulate")

# Install the Miniconda Python distribution
reticulate::install_miniconda()

# Install the actual package
reticulate::py_install("hu-neuro-pipeline", pip = TRUE, python_version = "3.8")
```

\bigskip

```{r, echo=FALSE, fig.align="right", out.width="15%"}
include_if_exists("slides/figures/reticulate.png")
```

## General usage

```{r, eval=FALSE}
# Import the Python package
pipeline <- reticulate::import("pipeline")

# Run the pipeline
res <- pipeline$group_pipeline(...)
```

## A simple example

```{r, eval=FALSE}
# Import the Python package
pipeline <- reticulate::import("pipeline")

# Run the pipeline
res <- pipeline$group_pipeline(
  # Input/output paths
  vhdr_files = "data/raw",
  log_files = "data/log",
  output_dir = "output",
  # Preprocessing options
  ocular_correction = "data/cali",
  # Epoching options
  triggers = c(201:208, 211:218),
  components = list(
    "name" = c("N2", "P3b"),
    "tmin" = c(0.25, 0.4),
    "tmax" = c(0.35, 0.55),
    "roi" = list(
      c("FC1", "FC2", "C1", "C2", "Cz"),
      c("CP3", "CP1", "CPz", "CP2", "CP4", "P3", "Pz", "P4", "PO3", "POz", "PO4")
    )
  ),
  # Averaging options
  average_by = c("n_b", "n_b/DeviantPosRL")
)
```

## Pipeline inputs

```{r, eval=FALSE}
# Input/output paths
vhdr_files = "data/raw",
log_files = "data/log",
output_dir = "output",
```

- Directory or list of raw EEG files (`.vhdr`)

- Directory or list of behavioral log files (`.txt`/`.tsv`/`.csv`)

- Output directory

## Pipeline inputs

```{r, eval=FALSE}
# Preprocessing options
ocular_correction = "data/cali",
```

- Ocular correction:

    - Path or list of BESA files (`.matrix`) or

    - `"auto"` for independent component analysis (ICA)

- Default bandpass filter (0.1--40 Hz)

## Pipeline inputs

```{r, eval=FALSE}
# Epoching options
triggers = c(201:208, 211:218),
components = list(
  "name" = c("N2", "P3b"),
  "tmin" = c(0.25, 0.4),
  "tmax" = c(0.35, 0.55),
  "roi" = list(
    c("FC1", "FC2", "C1", "C2", "Cz"),
    c("CP3", "CP1", "CPz", "CP2", "CP4", "P3", "Pz", "P4", "PO3", "POz", "PO4")
  )
),
```

- List of numerical EEG triggers

- List of ERP component definitions:

    - `name`: Column names for each component

    - `tmin` + `tmax`: Onset and offset times (in s)

    - `roi`: List of channel names for each component

## Pipeline inputs

```{r, eval=FALSE}
# Averaging options
average_by = c("n_b", "DeviantPosRL", "n_b/DeviantPosRL")
```

- List of column names (for main effects) and combinations of column names (for interaction effects, seperated by `"/"`)

## More Pipeline inputs

- Downsampling (`downsample_sfreq`)

- Interpolate bad channels (`bad_channels`)

- Frequency filter (`highpass_freq`, `lowpass_freq`)

- Epoch duration (`epochs_tmin`, `epochs_tmax`)

- Baseline duration (`baseline_tmin`, `baseline_tmax`)

- Skip log file rows (`skip_log_rows`, `skip_log_conditions`)

- Threshold for artifact rejection (`reject_peak_to_peak`)

\tiny

See https://github.com/alexenge/hu-neuro-pipeline/blob/main/docs/inputs.md

## Pipeline outputs

Extract directly from the pipeline run:

```{r, eval=FALSE}
trials <- res[[1]]   # Single trial data frame
evokeds <- res[[2]]  # Evokeds data frame
config <- res[[3]]   # List of pipeline options
```

Or read from the output directory:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
trials <- read_csv("output/trials.csv")
evokeds <- read_csv("output/ave.csv")
config <- jsonlite::read_json("output/config.json")
```

\tiny

See https://github.com/alexenge/hu-neuro-pipeline/blob/main/docs/outputs.md

## Pipeline outputs

```{r, message=FALSE, warning=FALSE}
# Single trial data frame
print(trials)
```

## Pipeline outputs

```{r, results="hold", out.width="50%"}
# Single trial N2 mean amplitudes
summary(trials$N2)
plot(density(trials$N2, na.rm = TRUE))
```

## Pipeline outputs

```{r}
# Linear mixed-effects model
form <- N2 ~ n_b * DeviantPosRL + (1 | participant_id)
mod <- lme4::lmer(form, trials)
summary(mod)
```

## Pipeline outputs

```{r, eval=TRUE, out.width="50%", message=FALSE, warning=FALSE}
# Single trial N2 mean amplitudes by condition
trials %>%
  ggplot(aes(x = DeviantPosRL, y = N2, color = n_b, group = n_b)) +
  geom_point(position = position_jitterdodge(0.3), alpha = 0.1) +
  stat_summary(
    geom = "line",
    size = 2.,
    position = position_dodge(0.75)
  ) +
  theme_classic(base_size = 30)
```

## Pipeline outputs

```{r}
# Evokeds by participant and condition
print(evokeds)
```

## Pipeline outputs

```{r, eval=FALSE, out.width="50%", message=FALSE, warning=FALSE}
# Evokeds by participant/condition
evokeds %>%
  filter(average_by == "n_b/DeviantPosRL") %>%
  Rmisc::summarySEwithin(
    measurevar = "N2",
    withinvars = c("time", "n_b", "DeviantPosRL"),
    idvar = "participant_id"
  ) %>%
  mutate(time = as.numeric(levels(time))[time]) %>%
  ggplot(aes(
    x = time,
    y = N2,
    ymin = N2 - se,
    ymax = N2 + se,
    color = n_b,
    fill = n_b
  )) +
  facet_wrap(~DeviantPosRL) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_line(size = 1) +
  geom_ribbon(color = NA, alpha = 0.2) +
  coord_cartesian(xlim = c(-0.2, 0.8)) +
  theme_classic(base_size = 20)
```

## Pipeline outputs

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=5}
# Evokeds by participant/condition (core repeated for creating the plot)
evokeds %>%
  filter(average_by == "n_b/DeviantPosRL") %>%
  Rmisc::summarySEwithin(
    measurevar = "N2",
    withinvars = c("time", "n_b", "DeviantPosRL"),
    idvar = "participant_id"
  ) %>%
  mutate(time = as.numeric(levels(time))[time]) %>%
  ggplot(aes(
    x = time,
    y = N2,
    ymin = N2 - se,
    ymax = N2 + se,
    color = n_b,
    fill = n_b
  )) +
  facet_wrap(~DeviantPosRL) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_line(size = 1) +
  geom_ribbon(color = NA, alpha = 0.2) +
  coord_cartesian(xlim = c(-0.2, 0.8)) +
  theme_classic(base_size = 20)
```

## Pipeline outputs

```{r}
# List of pipeline options
names(config)
```

```{r, results="hold"}
# Number of rejected epochs per participant
lengths(config$rejected_epochs)
```

## Cluster-based permutation tests

```{r, eval=FALSE}
# Permutation test options
perm_contrasts = list(
  c("blurr", "normal"),
  c("blurr/re", "blurr/li"),
  c("normal/re", "normal/li")
)
```

```{r, message=FALSE, warning=FALSE}
# Permutation test outputs
clusters <- read_csv("output/clusters.csv") # or clusters <- res[[4]]
print(na.omit(clusters))
```

## Automated tools

- Reject bad epochs (`reject_peak_to_peak = 200`)

  - Using per-channel peak-to-peak amplitudes

- Ocular correction (`ocular_correction = "auto"`)

  - FastICA [@hyvarinen1999] + correlation with HEOG/VEOG

- Interpolate bad channels (`bad_channel = "auto"`)

  - Based on per-channel standard error across epochs

```{r, echo=FALSE, fig.align="right", out.width="46%"}
include_if_exists("slides/figures/automate.png")
```

## One more thing

::: columns

:::: column

```{r, eval=FALSE}
# Auto-match log files to triggers
triggers_column = "trigger",
```

- Have such a column? Great!

- If not, create in R and pass data frames as `log_files`

::::

:::: column

```{r, echo=FALSE, fig.align="right", out.width="100%"}
include_if_exists("slides/figures/one_more_thing.jpeg")
```

::::

:::

## Plans

- Automated tests

- Better HTML reports

- Mixed models with `pymer4` (?)

- New flavors of permutation tests:

    - Cluster test on ANOVAs or mixed models [@frossard2021]

    - Cluster depth test [@frossard2022]

- BIDS interface

- Command line interface + Docker app

## References

\scriptsize
